{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d7B0DE71lwXI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"Struct Type\") \\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = [\n",
        "    (\"U001\",\"Abhishek\",28,\"Hyderabad\",50000),\n",
        "    (\"U002\",\"Neha\",32,\"Delhi\",62000),\n",
        "    (\"U003\",\"Ravi\",25,\"Bangalore\",45000),\n",
        "    (\"U004\",\"Pooja\",29,\"Mumbai\",58000)\n",
        "]"
      ],
      "metadata": {
        "id": "TjQlFmFEm3Ho"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import (StructType, StructField, StringType, IntegerType, LongType)"
      ],
      "metadata": {
        "id": "rH3uHxzdm_e5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(), nullable=False),\n",
        "    StructField(\"name\", StringType(), nullable=True),\n",
        "    StructField(\"age\", IntegerType(), nullable=True),\n",
        "    StructField(\"city\", StringType(), nullable=True),\n",
        "    StructField(\"salary\", LongType(), nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "bEGojgg4nQ-Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users = spark.createDataFrame(data=raw_data, schema=user_schema)\n",
        "df_users.printSchema()\n",
        "df_users.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpKwEEpJnVNp",
        "outputId": "1a5bf33f-94d1-440c-9b3e-805f3453d8e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------+--------+---+---------+------+\n",
            "|user_id|    name|age|     city|salary|\n",
            "+-------+--------+---+---------+------+\n",
            "|   U001|Abhishek| 28|Hyderabad| 50000|\n",
            "|   U002|    Neha| 32|    Delhi| 62000|\n",
            "|   U003|    Ravi| 25|Bangalore| 45000|\n",
            "|   U004|   Pooja| 29|   Mumbai| 58000|\n",
            "+-------+--------+---+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wrong data"
      ],
      "metadata": {
        "id": "nibTmiJ0royE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data2 = [ (\"U005\", \"Amit\", \"Thirty\", \"Chennai\", 40000)]"
      ],
      "metadata": {
        "id": "k46-n_81niph"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users = spark.createDataFrame(data=raw_data2, schema=user_schema)\n",
        "#wont happen since age is not an int"
      ],
      "metadata": {
        "id": "OQKV0BZ_nu89"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ArrayType"
      ],
      "metadata": {
        "id": "75LRx7tnrtpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import ArrayType"
      ],
      "metadata": {
        "id": "_rKZpHN9qyul"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_data = [\n",
        "    (\"U001\",[\"AI\",\"ML\",\"Cloud\"]),\n",
        "    (\"U002\",[\"Testing\",\"Automation\"]),\n",
        "    (\"U003\",[\"Data Engineering\",\"Spark\",\"Kafka\"]),\n",
        "    (\"U004\",[\"UI/UX\"])\n",
        "]"
      ],
      "metadata": {
        "id": "2vh6jmKrrFie"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(), nullable=False),\n",
        "    StructField(\"interests\", ArrayType(StringType()), nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "M_BaVHb2q_93"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_interests = spark.createDataFrame(interest_data, interest_schema)\n",
        "df_interests.printSchema()\n",
        "df_interests.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAe_rJQJrS9A",
        "outputId": "4879e0b6-8e10-471f-fac3-015b2192e31a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- interests: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+--------------------------------+\n",
            "|user_id|interests                       |\n",
            "+-------+--------------------------------+\n",
            "|U001   |[AI, ML, Cloud]                 |\n",
            "|U002   |[Testing, Automation]           |\n",
            "|U003   |[Data Engineering, Spark, Kafka]|\n",
            "|U004   |[UI/UX]                         |\n",
            "+-------+--------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explode"
      ],
      "metadata": {
        "id": "aZ9xcUbFsIy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df_interests.select(\"user_id\",\n",
        "                    explode(\"interests\").alias(\"interest\")\n",
        "                    ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6gOyh2Sre94",
        "outputId": "0f8956fd-dfcc-4b5b-df40-4c7bfaf1f1f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+\n",
            "|user_id|        interest|\n",
            "+-------+----------------+\n",
            "|   U001|              AI|\n",
            "|   U001|              ML|\n",
            "|   U001|           Cloud|\n",
            "|   U002|         Testing|\n",
            "|   U002|      Automation|\n",
            "|   U003|Data Engineering|\n",
            "|   U003|           Spark|\n",
            "|   U003|           Kafka|\n",
            "|   U004|           UI/UX|\n",
            "+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mapType"
      ],
      "metadata": {
        "id": "N_djAP0VsrUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import MapType"
      ],
      "metadata": {
        "id": "hNAXj2--sE1V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_data = [\n",
        "    (\"U001\",{\"mobile\":120,\"laptop\":300}),\n",
        "    (\"U002\",{\"tablet\":80}),\n",
        "    (\"U003\",{\"mobile\":200,\"desktop\":400}),\n",
        "    (\"U004\",{\"laptop\":250})\n",
        "]"
      ],
      "metadata": {
        "id": "k5Sm6raMs2JJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(), nullable=False),\n",
        "    StructField(\"devices\", MapType(StringType(), IntegerType()), nullable=True)\n",
        "])"
      ],
      "metadata": {
        "id": "c5YvkdxUs8za"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_devices = spark.createDataFrame(device_data, device_schema)\n",
        "df_devices.printSchema()\n",
        "df_devices.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjyhFG57tKDZ",
        "outputId": "761be866-b826-4b4a-da3d-80ecc269b372"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- devices: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: integer (valueContainsNull = true)\n",
            "\n",
            "+-------+--------------------+\n",
            "|user_id|             devices|\n",
            "+-------+--------------------+\n",
            "|   U001|{mobile -> 120, l...|\n",
            "|   U002|      {tablet -> 80}|\n",
            "|   U003|{mobile -> 200, d...|\n",
            "|   U004|     {laptop -> 250}|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nested data"
      ],
      "metadata": {
        "id": "nVQ8Ik4Ht9tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nested_data = [\n",
        "    (\"U001\",(\"Hyderabad\",\"Telangana\",500081)),\n",
        "    (\"U002\",(\"Delhi\",\"Delhi\",110001)),\n",
        "    (\"U003\",(\"Bangalore\",\"Karnataka\",560001))\n",
        "]"
      ],
      "metadata": {
        "id": "nZad0NHnt_DX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address_schema = StructType([\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"state\", StringType(), True),\n",
        "    StructField(\"pincode\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "profile_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(), True),\n",
        "    StructField(\"address\", address_schema, True),\n",
        "])"
      ],
      "metadata": {
        "id": "Tf_rfh1quDyZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_profile = spark.createDataFrame(nested_data, profile_schema)\n",
        "df_profile.printSchema()\n",
        "df_profile.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFRTcaT5u-ym",
        "outputId": "fc321268-8660-4aa2-8819-0e1956b27794"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- state: string (nullable = true)\n",
            " |    |-- pincode: integer (nullable = true)\n",
            "\n",
            "+-------+--------------------+\n",
            "|user_id|             address|\n",
            "+-------+--------------------+\n",
            "|   U001|{Hyderabad, Telan...|\n",
            "|   U002|{Delhi, Delhi, 11...|\n",
            "|   U003|{Bangalore, Karna...|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_profile.select(\n",
        "    \"user_id\",\n",
        "    \"address.city\",\n",
        "    \"address.state\"\n",
        "\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0eOAXsjvGMk",
        "outputId": "caf96ca3-e4bc-41ea-d0dc-39bd1198b1e1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+\n",
            "|user_id|     city|    state|\n",
            "+-------+---------+---------+\n",
            "|   U001|Hyderabad|Telangana|\n",
            "|   U002|    Delhi|    Delhi|\n",
            "|   U003|Bangalore|Karnataka|\n",
            "+-------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df_users.withColumn(\n",
        "    \"salary_int\",\n",
        "    col(\"salary\").cast(\"int\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MRZ0ZWSwD7c",
        "outputId": "fae662c4-5d70-4ac3-976a-acf754a202f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: string, name: string, age: int, city: string, salary: bigint, salary_int: int]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "df_orders.withColumn(\n",
        "    \"order_date\",\n",
        "    to_date(col(\"order_date\"), \"yyyy-MM-dd\"))"
      ],
      "metadata": {
        "id": "FqleOnMVySFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}