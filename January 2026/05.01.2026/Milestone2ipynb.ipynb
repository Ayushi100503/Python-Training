{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hTK6Ookiyt7p"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "spark = SparkSession.builder \\\n",
        ".appName('Large-Scale Order Processing System') \\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "rJciAJs7y2rW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1 — Data Ingestion & Schema"
      ],
      "metadata": {
        "id": "Mg4wBDtfzmo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Read the CSV le using PySpark ensuring the job does not fail due to bad data.\n"
      ],
      "metadata": {
        "id": "D_zhJiiszq16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = spark.read\\\n",
        ".option(\"header\", True) \\\n",
        ".option(\"badRecordsPath\", \"/tmp/bad_records\") \\\n",
        ".csv(\"/content/orders_raw.csv\")"
      ],
      "metadata": {
        "id": "Vcq0a5_Yy5fB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explain why reading all columns as StringType is preferred initially.\n"
      ],
      "metadata": {
        "id": "qqPBnPAlzuvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#When working with raw data, especially from sources like CSVs, it's often best practice to initially load all columns as StringType. This approach offers several significant advantages for data quality and robust processing."
      ],
      "metadata": {
        "id": "-dot0aPWzeM0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Print schema and total record count."
      ],
      "metadata": {
        "id": "YL9xYWutzxoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.printSchema()\n",
        "df_raw.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHvheciTz0PK",
        "outputId": "fa50e430-d997-4a12-8962-47da2750102e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 2 — Data Cleaning & Validation"
      ],
      "metadata": {
        "id": "GuSLYWsXz5WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Clean leading/trailing spaces from string columns.\n"
      ],
      "metadata": {
        "id": "3lconQajz9Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, trim\n",
        "df = df_raw.select([trim(col(c)).alias(c) for c in df_raw.columns])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9IXMHzoz8pc",
        "outputId": "9c94860a-0df1-4dfd-fcd0-45cdb8926104"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|   order_id|customer_id|     city|   category|    product| amount|order_date|   status|\n",
            "+-----------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|ORD00000000|    C000000|hyderabad|    grocery|        Oil|invalid|01/01/2024|Cancelled|\n",
            "|ORD00000001|    C000001|     Pune|    Grocery|      Sugar|  35430|2024-01-02|Completed|\n",
            "|ORD00000002|    C000002|     Pune|Electronics|     Mobile|  65358|2024-01-03|Completed|\n",
            "|ORD00000003|    C000003|Bangalore|Electronics|     Laptop|   5558|2024-01-04|Completed|\n",
            "|ORD00000004|    C000004|     Pune|       Home|AirPurifier|  33659|2024-01-05|Completed|\n",
            "|ORD00000005|    C000005|    Delhi|    Fashion|      Jeans|   8521|2024-01-06|Completed|\n",
            "|ORD00000006|    C000006|    Delhi|    Grocery|      Sugar|  42383|2024-01-07|Completed|\n",
            "|ORD00000007|    C000007|     Pune|    Grocery|       Rice|  45362|2024-01-08|Completed|\n",
            "|ORD00000008|    C000008|Bangalore|    Fashion|      Jeans|  10563|2024-01-09|Completed|\n",
            "|ORD00000009|    C000009|  Kolkata|Electronics|     Laptop|  63715|2024-01-10|Completed|\n",
            "|ORD00000010|    C000010|Bangalore|    Grocery|      Sugar|  66576|2024-01-11|Completed|\n",
            "|ORD00000011|    C000011|  Kolkata|Electronics|     Tablet|  50318|12/01/2024|Completed|\n",
            "|ORD00000012|    C000012|Bangalore|    Grocery|      Sugar|  84768|2024-01-13|Completed|\n",
            "|ORD00000013|    C000013|     Pune|    Fashion|     TShirt|  79121|2024/01/14|Completed|\n",
            "|ORD00000014|    C000014|   Mumbai|Electronics|     Tablet|  79469|2024-01-15|Completed|\n",
            "|ORD00000015|    C000015|     Pune|Electronics|     Mobile|  81018|2024-01-16|Completed|\n",
            "|ORD00000016|    C000016|   Mumbai|       Home|      Mixer|  64225|2024-01-17|Completed|\n",
            "|ORD00000017|    C000017|bangalore|    Grocery|        Oil|  69582|2024-01-18|Completed|\n",
            "|ORD00000018|    C000018|  Kolkata|    Fashion|      Jeans|  50424|2024-01-19|Completed|\n",
            "|ORD00000019|    C000019|   Mumbai|Electronics|     Mobile|invalid|2024-01-20|Completed|\n",
            "+-----------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Standardize city , category , and product values.\n"
      ],
      "metadata": {
        "id": "wg93zIEk0BZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower, initcap\n",
        "df = df.withColumn(\"city\", initcap(lower(col(\"city\"))))\\\n",
        ".withColumn(\"category\", lower(col(\"category\")))\\\n",
        ".withColumn(\"product\", lower(col(\"product\")))\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAYLMSuV0Bxb",
        "outputId": "2ec3f137-e2b2-4352-c08d-8bc8e5442933"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|   order_id|customer_id|     city|   category|    product| amount|order_date|   status|\n",
            "+-----------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|ORD00000000|    C000000|Hyderabad|    grocery|        oil|invalid|01/01/2024|Cancelled|\n",
            "|ORD00000001|    C000001|     Pune|    grocery|      sugar|  35430|2024-01-02|Completed|\n",
            "|ORD00000002|    C000002|     Pune|electronics|     mobile|  65358|2024-01-03|Completed|\n",
            "|ORD00000003|    C000003|Bangalore|electronics|     laptop|   5558|2024-01-04|Completed|\n",
            "|ORD00000004|    C000004|     Pune|       home|airpurifier|  33659|2024-01-05|Completed|\n",
            "|ORD00000005|    C000005|    Delhi|    fashion|      jeans|   8521|2024-01-06|Completed|\n",
            "|ORD00000006|    C000006|    Delhi|    grocery|      sugar|  42383|2024-01-07|Completed|\n",
            "|ORD00000007|    C000007|     Pune|    grocery|       rice|  45362|2024-01-08|Completed|\n",
            "|ORD00000008|    C000008|Bangalore|    fashion|      jeans|  10563|2024-01-09|Completed|\n",
            "|ORD00000009|    C000009|  Kolkata|electronics|     laptop|  63715|2024-01-10|Completed|\n",
            "|ORD00000010|    C000010|Bangalore|    grocery|      sugar|  66576|2024-01-11|Completed|\n",
            "|ORD00000011|    C000011|  Kolkata|electronics|     tablet|  50318|12/01/2024|Completed|\n",
            "|ORD00000012|    C000012|Bangalore|    grocery|      sugar|  84768|2024-01-13|Completed|\n",
            "|ORD00000013|    C000013|     Pune|    fashion|     tshirt|  79121|2024/01/14|Completed|\n",
            "|ORD00000014|    C000014|   Mumbai|electronics|     tablet|  79469|2024-01-15|Completed|\n",
            "|ORD00000015|    C000015|     Pune|electronics|     mobile|  81018|2024-01-16|Completed|\n",
            "|ORD00000016|    C000016|   Mumbai|       home|      mixer|  64225|2024-01-17|Completed|\n",
            "|ORD00000017|    C000017|Bangalore|    grocery|        oil|  69582|2024-01-18|Completed|\n",
            "|ORD00000018|    C000018|  Kolkata|    fashion|      jeans|  50424|2024-01-19|Completed|\n",
            "|ORD00000019|    C000019|   Mumbai|electronics|     mobile|invalid|2024-01-20|Completed|\n",
            "+-----------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Convert amount to integer safely, handling invalid values.\n"
      ],
      "metadata": {
        "id": "3m2ad-gS0Fjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, regexp_replace, nullif, lit\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Remove all non-digit characters from the 'amount' column\n",
        "cleaned_amount_col = regexp_replace(col(\"amount\"), \"[^0-9]\", \"\")\n",
        "\n",
        "# Convert empty strings (e.g., from 'invalid' or non-numeric entries) to NULL\n",
        "nullable_amount_col = nullif(cleaned_amount_col, lit(\"\"))\n",
        "\n",
        "# Cast the cleaned and null-handled column to IntegerType\n",
        "df = df.withColumn(\"amount\", nullable_amount_col.cast(IntegerType()))\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIvrUBGN1ysj",
        "outputId": "ff18781c-243c-4bf2-ea27-ad844b0c4712"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-----------+------+----------+---------+\n",
            "|   order_id|customer_id|     city|   category|    product|amount|order_date|   status|\n",
            "+-----------+-----------+---------+-----------+-----------+------+----------+---------+\n",
            "|ORD00000000|    C000000|Hyderabad|    grocery|        oil|  NULL|01/01/2024|Cancelled|\n",
            "|ORD00000001|    C000001|     Pune|    grocery|      sugar| 35430|2024-01-02|Completed|\n",
            "|ORD00000002|    C000002|     Pune|electronics|     mobile| 65358|2024-01-03|Completed|\n",
            "|ORD00000003|    C000003|Bangalore|electronics|     laptop|  5558|2024-01-04|Completed|\n",
            "|ORD00000004|    C000004|     Pune|       home|airpurifier| 33659|2024-01-05|Completed|\n",
            "|ORD00000005|    C000005|    Delhi|    fashion|      jeans|  8521|2024-01-06|Completed|\n",
            "|ORD00000006|    C000006|    Delhi|    grocery|      sugar| 42383|2024-01-07|Completed|\n",
            "|ORD00000007|    C000007|     Pune|    grocery|       rice| 45362|2024-01-08|Completed|\n",
            "|ORD00000008|    C000008|Bangalore|    fashion|      jeans| 10563|2024-01-09|Completed|\n",
            "|ORD00000009|    C000009|  Kolkata|electronics|     laptop| 63715|2024-01-10|Completed|\n",
            "|ORD00000010|    C000010|Bangalore|    grocery|      sugar| 66576|2024-01-11|Completed|\n",
            "|ORD00000011|    C000011|  Kolkata|electronics|     tablet| 50318|12/01/2024|Completed|\n",
            "|ORD00000012|    C000012|Bangalore|    grocery|      sugar| 84768|2024-01-13|Completed|\n",
            "|ORD00000013|    C000013|     Pune|    fashion|     tshirt| 79121|2024/01/14|Completed|\n",
            "|ORD00000014|    C000014|   Mumbai|electronics|     tablet| 79469|2024-01-15|Completed|\n",
            "|ORD00000015|    C000015|     Pune|electronics|     mobile| 81018|2024-01-16|Completed|\n",
            "|ORD00000016|    C000016|   Mumbai|       home|      mixer| 64225|2024-01-17|Completed|\n",
            "|ORD00000017|    C000017|Bangalore|    grocery|        oil| 69582|2024-01-18|Completed|\n",
            "|ORD00000018|    C000018|  Kolkata|    fashion|      jeans| 50424|2024-01-19|Completed|\n",
            "|ORD00000019|    C000019|   Mumbai|electronics|     mobile|  NULL|2024-01-20|Completed|\n",
            "+-----------+-----------+---------+-----------+-----------+------+----------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Parse order_date supporting multiple date formats.\n"
      ],
      "metadata": {
        "id": "iH2TVSNY0LtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"order_date_clean\",\n",
        "    F.coalesce(\n",
        "        F.expr(\"try_to_timestamp(order_date, 'yyyy-MM-dd')\").cast(\"date\"),\n",
        "        F.expr(\"try_to_timestamp(order_date, 'yyyy/MM/dd')\").cast(\"date\"),\n",
        "        F.expr(\"try_to_timestamp(order_date, 'dd/MM/yyyy')\").cast(\"date\"),\n",
        "        F.expr(\"try_to_timestamp(order_date, 'dd-MM-yyyy')\").cast(\"date\")\n",
        "    )\n",
        ").drop(\"order_date\", \"order_date_parsed\").withColumnRenamed(\"order_date_clean\", \"order_date\")\n",
        "\n",
        "df.select(\"order_date\").show(20, truncate=False)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5KVg1aD335_",
        "outputId": "7425feaf-7124-4941-f16c-a245caf39973"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|order_date|\n",
            "+----------+\n",
            "|2024-01-01|\n",
            "|2024-01-02|\n",
            "|2024-01-03|\n",
            "|2024-01-04|\n",
            "|2024-01-05|\n",
            "|2024-01-06|\n",
            "|2024-01-07|\n",
            "|2024-01-08|\n",
            "|2024-01-09|\n",
            "|2024-01-10|\n",
            "|2024-01-11|\n",
            "|2024-01-12|\n",
            "|2024-01-13|\n",
            "|2024-01-14|\n",
            "|2024-01-15|\n",
            "|2024-01-16|\n",
            "|2024-01-17|\n",
            "|2024-01-18|\n",
            "|2024-01-19|\n",
            "|2024-01-20|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Identify and handle invalid or null records."
      ],
      "metadata": {
        "id": "tWWx2EPC0Nwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total records after cleaning and validation: {df_valid.count()}\")\n",
        "invalid_records_count = df.count() - df_valid.count()\n",
        "print(f\"Number of invalid/null records dropped: {invalid_records_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvn1oVJG5kHT",
        "outputId": "31949d9e-23ff-4d32-9917-5ca109efd5c5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total records after cleaning and validation: 272458\n",
            "Number of invalid/null records dropped: 27542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 3 — Business Rules\n"
      ],
      "metadata": {
        "id": "PnG_sRDk3Gw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Remove duplicate records based on order_id .\n"
      ],
      "metadata": {
        "id": "cJ9rg0Fa3NcD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbme7Tl00Ogo",
        "outputId": "a661cba2-c2a7-4d96-debb-78844bccd63b"
      },
      "source": [
        "df_valid = df.filter(\n",
        "    F.col(\"order_id\").isNotNull() &\n",
        "    F.col(\"order_date\").isNotNull() &\n",
        "    F.col(\"amount\").isNotNull()\n",
        ")\n",
        "df_valid.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|   order_id|customer_id|     city|   category|    product|amount|   status|order_date|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|ORD00000001|    C000001|     Pune|    grocery|      sugar| 35430|Completed|2024-01-02|\n",
            "|ORD00000002|    C000002|     Pune|electronics|     mobile| 65358|Completed|2024-01-03|\n",
            "|ORD00000003|    C000003|Bangalore|electronics|     laptop|  5558|Completed|2024-01-04|\n",
            "|ORD00000004|    C000004|     Pune|       home|airpurifier| 33659|Completed|2024-01-05|\n",
            "|ORD00000005|    C000005|    Delhi|    fashion|      jeans|  8521|Completed|2024-01-06|\n",
            "|ORD00000006|    C000006|    Delhi|    grocery|      sugar| 42383|Completed|2024-01-07|\n",
            "|ORD00000007|    C000007|     Pune|    grocery|       rice| 45362|Completed|2024-01-08|\n",
            "|ORD00000008|    C000008|Bangalore|    fashion|      jeans| 10563|Completed|2024-01-09|\n",
            "|ORD00000009|    C000009|  Kolkata|electronics|     laptop| 63715|Completed|2024-01-10|\n",
            "|ORD00000010|    C000010|Bangalore|    grocery|      sugar| 66576|Completed|2024-01-11|\n",
            "|ORD00000011|    C000011|  Kolkata|electronics|     tablet| 50318|Completed|2024-01-12|\n",
            "|ORD00000012|    C000012|Bangalore|    grocery|      sugar| 84768|Completed|2024-01-13|\n",
            "|ORD00000013|    C000013|     Pune|    fashion|     tshirt| 79121|Completed|2024-01-14|\n",
            "|ORD00000014|    C000014|   Mumbai|electronics|     tablet| 79469|Completed|2024-01-15|\n",
            "|ORD00000015|    C000015|     Pune|electronics|     mobile| 81018|Completed|2024-01-16|\n",
            "|ORD00000016|    C000016|   Mumbai|       home|      mixer| 64225|Completed|2024-01-17|\n",
            "|ORD00000017|    C000017|Bangalore|    grocery|        oil| 69582|Completed|2024-01-18|\n",
            "|ORD00000018|    C000018|  Kolkata|    fashion|      jeans| 50424|Completed|2024-01-19|\n",
            "|ORD00000020|    C000020|  Kolkata|    grocery|       rice| 58757|Cancelled|2024-01-21|\n",
            "|ORD00000021|    C000021|    Delhi|electronics|     tablet| 20654|Completed|2024-01-22|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJvYF0aF5-mg",
        "outputId": "325893c1-c570-464e-ad37-fc9887a1cab8"
      },
      "source": [
        "df_dedup = df_valid.dropDuplicates([\"order_id\"])\n",
        "df_dedup.show(20, truncate=False)\n",
        "df_dedup.count()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|order_id   |customer_id|city     |category   |product    |amount|status   |order_date|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|ORD00000001|C000001    |Pune     |grocery    |sugar      |35430 |Completed|2024-01-02|\n",
            "|ORD00000007|C000007    |Pune     |grocery    |rice       |45362 |Completed|2024-01-08|\n",
            "|ORD00000008|C000008    |Bangalore|fashion    |jeans      |10563 |Completed|2024-01-09|\n",
            "|ORD00000010|C000010    |Bangalore|grocery    |sugar      |66576 |Completed|2024-01-11|\n",
            "|ORD00000011|C000011    |Kolkata  |electronics|tablet     |50318 |Completed|2024-01-12|\n",
            "|ORD00000012|C000012    |Bangalore|grocery    |sugar      |84768 |Completed|2024-01-13|\n",
            "|ORD00000014|C000014    |Mumbai   |electronics|tablet     |79469 |Completed|2024-01-15|\n",
            "|ORD00000015|C000015    |Pune     |electronics|mobile     |81018 |Completed|2024-01-16|\n",
            "|ORD00000017|C000017    |Bangalore|grocery    |oil        |69582 |Completed|2024-01-18|\n",
            "|ORD00000022|C000022    |Mumbai   |grocery    |sugar      |48832 |Completed|2024-01-23|\n",
            "|ORD00000023|C000023    |Hyderabad|electronics|mobile     |12000 |Completed|2024-01-24|\n",
            "|ORD00000024|C000024    |Bangalore|home       |mixer      |18082 |Completed|2024-01-25|\n",
            "|ORD00000025|C000025    |Bangalore|home       |airpurifier|58248 |Completed|2024-01-26|\n",
            "|ORD00000028|C000028    |Mumbai   |grocery    |sugar      |70675 |Completed|2024-01-29|\n",
            "|ORD00000030|C000030    |Pune     |home       |airpurifier|52112 |Completed|2024-01-31|\n",
            "|ORD00000031|C000031    |Chennai  |grocery    |oil        |51151 |Completed|2024-02-01|\n",
            "|ORD00000032|C000032    |Chennai  |home       |vacuum     |75797 |Completed|2024-02-02|\n",
            "|ORD00000034|C000034    |Pune     |grocery    |sugar      |40915 |Completed|2024-02-04|\n",
            "|ORD00000036|C000036    |Kolkata  |grocery    |oil        |29253 |Completed|2024-02-06|\n",
            "|ORD00000039|C000039    |Pune     |grocery    |oil        |73088 |Completed|2024-02-09|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "only showing top 20 rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272458"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Filter only records with status = Completed .\n"
      ],
      "metadata": {
        "id": "pyEfhqmm3Pso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_completed = df_dedup.filter(col(\"status\") == \"Completed\")\n",
        "df_completed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZspgo1W3RYP",
        "outputId": "d0098b2b-7fa6-4433-9018-3e7be5b4e898"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|   order_id|customer_id|     city|   category|    product|amount|   status|order_date|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|ORD00000001|    C000001|     Pune|    grocery|      sugar| 35430|Completed|2024-01-02|\n",
            "|ORD00000007|    C000007|     Pune|    grocery|       rice| 45362|Completed|2024-01-08|\n",
            "|ORD00000008|    C000008|Bangalore|    fashion|      jeans| 10563|Completed|2024-01-09|\n",
            "|ORD00000010|    C000010|Bangalore|    grocery|      sugar| 66576|Completed|2024-01-11|\n",
            "|ORD00000011|    C000011|  Kolkata|electronics|     tablet| 50318|Completed|2024-01-12|\n",
            "|ORD00000012|    C000012|Bangalore|    grocery|      sugar| 84768|Completed|2024-01-13|\n",
            "|ORD00000014|    C000014|   Mumbai|electronics|     tablet| 79469|Completed|2024-01-15|\n",
            "|ORD00000015|    C000015|     Pune|electronics|     mobile| 81018|Completed|2024-01-16|\n",
            "|ORD00000017|    C000017|Bangalore|    grocery|        oil| 69582|Completed|2024-01-18|\n",
            "|ORD00000022|    C000022|   Mumbai|    grocery|      sugar| 48832|Completed|2024-01-23|\n",
            "|ORD00000023|    C000023|Hyderabad|electronics|     mobile| 12000|Completed|2024-01-24|\n",
            "|ORD00000024|    C000024|Bangalore|       home|      mixer| 18082|Completed|2024-01-25|\n",
            "|ORD00000025|    C000025|Bangalore|       home|airpurifier| 58248|Completed|2024-01-26|\n",
            "|ORD00000028|    C000028|   Mumbai|    grocery|      sugar| 70675|Completed|2024-01-29|\n",
            "|ORD00000030|    C000030|     Pune|       home|airpurifier| 52112|Completed|2024-01-31|\n",
            "|ORD00000031|    C000031|  Chennai|    grocery|        oil| 51151|Completed|2024-02-01|\n",
            "|ORD00000032|    C000032|  Chennai|       home|     vacuum| 75797|Completed|2024-02-02|\n",
            "|ORD00000034|    C000034|     Pune|    grocery|      sugar| 40915|Completed|2024-02-04|\n",
            "|ORD00000036|    C000036|  Kolkata|    grocery|        oil| 29253|Completed|2024-02-06|\n",
            "|ORD00000039|    C000039|     Pune|    grocery|        oil| 73088|Completed|2024-02-09|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Validate record counts before and after ltering."
      ],
      "metadata": {
        "id": "E0fy91tx3Rx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total records after cleaning and validation: {df_valid.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39gV9NNS3SiB",
        "outputId": "ad5a73ac-b75d-4d71-d5ab-d902b67d0737"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total records after cleaning and validation: 272458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 4 — Performance & Optimization\n"
      ],
      "metadata": {
        "id": "JN1cxG2Y3T9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Identify operations that cause shu es.\n"
      ],
      "metadata": {
        "id": "bcVejPFu3gps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#groupBY, dropDuplicates, join, orderBy, window functions"
      ],
      "metadata": {
        "id": "Ice0meVw3ia_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Use explain(True) to analyze the execution plan.\n"
      ],
      "metadata": {
        "id": "GrpgNYdH3iyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dedup.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2D2XCwT3kZg",
        "outputId": "82d173ee-bf7a-41b9-b089-5463a2763942"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "Deduplicate [order_id#37]\n",
            "+- Filter ((isnotnull(order_id#37) AND isnotnull(order_date#1467)) AND isnotnull(amount#115))\n",
            "   +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_clean#1466 AS order_date#1467]\n",
            "      +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_clean#1466]\n",
            "         +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_parsed#150, order_date#1305, coalesce(cast(try_to_timestamp(order_date#1305, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#1305, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#1305, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#1305, Some(dd-MM-yyyy), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#1466]\n",
            "            +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_parsed#150, order_date_clean#1304 AS order_date#1305]\n",
            "               +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_parsed#150, order_date_clean#1304]\n",
            "                  +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, order_date#43, status#44, order_date_parsed#150, coalesce(cast(try_to_timestamp(order_date#43, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd-MM-yyyy), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#1304]\n",
            "                     +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, order_date#43, status#44, order_date_parsed#150, coalesce(cast(try_to_timestamp(order_date#43, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd-MM-yyyy), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#343]\n",
            "                        +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, order_date#43, status#44, coalesce(to_date(order_date#43, Some(yyyy-MM-dd), Some(Etc/UTC), true), to_date(order_date#43, Some(dd-MM-yyyy), Some(Etc/UTC), true), to_date(order_date#43, Some(MM/dd/yyyy), Some(Etc/UTC), true)) AS order_date_parsed#150]\n",
            "                           +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, cast(nullif(regexp_replace(amount#42, [^0-9], , 1), ) as int) AS amount#115, order_date#43, status#44]\n",
            "                              +- Project [order_id#37, customer_id#38, city#79, category#80, lower(product#41) AS product#81, amount#42, order_date#43, status#44]\n",
            "                                 +- Project [order_id#37, customer_id#38, city#79, lower(category#40) AS category#80, product#41, amount#42, order_date#43, status#44]\n",
            "                                    +- Project [order_id#37, customer_id#38, initcap(lower(city#39)) AS city#79, category#40, product#41, amount#42, order_date#43, status#44]\n",
            "                                       +- Project [trim(order_id#17, None) AS order_id#37, trim(customer_id#18, None) AS customer_id#38, trim(city#19, None) AS city#39, trim(category#20, None) AS category#40, trim(product#21, None) AS product#41, trim(amount#22, None) AS amount#42, trim(order_date#23, None) AS order_date#43, trim(status#24, None) AS status#44]\n",
            "                                          +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, customer_id: string, city: string, category: string, product: string, amount: int, status: string, order_date: date\n",
            "Deduplicate [order_id#37]\n",
            "+- Filter ((isnotnull(order_id#37) AND isnotnull(order_date#1467)) AND isnotnull(amount#115))\n",
            "   +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_clean#1466 AS order_date#1467]\n",
            "      +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_clean#1466]\n",
            "         +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_parsed#150, order_date#1305, coalesce(cast(try_to_timestamp(order_date#1305, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#1305, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#1305, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#1305, Some(dd-MM-yyyy), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#1466]\n",
            "            +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_parsed#150, order_date_clean#1304 AS order_date#1305]\n",
            "               +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, order_date_parsed#150, order_date_clean#1304]\n",
            "                  +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, order_date#43, status#44, order_date_parsed#150, coalesce(cast(try_to_timestamp(order_date#43, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd-MM-yyyy), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#1304]\n",
            "                     +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, order_date#43, status#44, order_date_parsed#150, coalesce(cast(try_to_timestamp(order_date#43, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(order_date#43, Some(dd-MM-yyyy), TimestampType, Some(Etc/UTC), false) as date)) AS order_date_clean#343]\n",
            "                        +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, order_date#43, status#44, coalesce(to_date(order_date#43, Some(yyyy-MM-dd), Some(Etc/UTC), true), to_date(order_date#43, Some(dd-MM-yyyy), Some(Etc/UTC), true), to_date(order_date#43, Some(MM/dd/yyyy), Some(Etc/UTC), true)) AS order_date_parsed#150]\n",
            "                           +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, cast(nullif(regexp_replace(amount#42, [^0-9], , 1), ) as int) AS amount#115, order_date#43, status#44]\n",
            "                              +- Project [order_id#37, customer_id#38, city#79, category#80, lower(product#41) AS product#81, amount#42, order_date#43, status#44]\n",
            "                                 +- Project [order_id#37, customer_id#38, city#79, lower(category#40) AS category#80, product#41, amount#42, order_date#43, status#44]\n",
            "                                    +- Project [order_id#37, customer_id#38, initcap(lower(city#39)) AS city#79, category#40, product#41, amount#42, order_date#43, status#44]\n",
            "                                       +- Project [trim(order_id#17, None) AS order_id#37, trim(customer_id#18, None) AS customer_id#38, trim(city#19, None) AS city#39, trim(category#20, None) AS category#40, trim(product#21, None) AS product#41, trim(amount#22, None) AS amount#42, trim(order_date#23, None) AS order_date#43, trim(status#24, None) AS status#44]\n",
            "                                          +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [order_id#37], [order_id#37, first(customer_id#38, false) AS customer_id#1913, first(city#79, false) AS city#1915, first(category#80, false) AS category#1917, first(product#81, false) AS product#1919, first(amount#115, false) AS amount#1921, first(status#44, false) AS status#1923, first(order_date#1467, false) AS order_date#1925]\n",
            "+- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, coalesce(cast(gettimestamp(order_date#1305, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#1305, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#1305, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#1305, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#1467]\n",
            "   +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, if ((_common_expr_0#1911 = )) null else cast(_common_expr_0#1911 as int) AS amount#115, status#44, coalesce(cast(gettimestamp(order_date#43, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#43, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#43, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#43, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#1305]\n",
            "      +- Project [trim(order_id#17, None) AS order_id#37, trim(customer_id#18, None) AS customer_id#38, initcap(lower(trim(city#19, None))) AS city#79, lower(trim(category#20, None)) AS category#80, lower(trim(product#21, None)) AS product#81, trim(order_date#23, None) AS order_date#43, trim(status#24, None) AS status#44, regexp_replace(trim(amount#22, None), [^0-9], , 1) AS _common_expr_0#1911]\n",
            "         +- Filter ((isnotnull(trim(order_id#17, None)) AND isnotnull(coalesce(cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)))) AND if ((regexp_replace(trim(amount#22, None), [^0-9], , 1) = )) false else isnotnull(cast(regexp_replace(trim(amount#22, None), [^0-9], , 1) as int)))\n",
            "            +- Relation [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] csv\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- SortAggregate(key=[order_id#37], functions=[first(customer_id#38, false), first(city#79, false), first(category#80, false), first(product#81, false), first(amount#115, false), first(status#44, false), first(order_date#1467, false)], output=[order_id#37, customer_id#1913, city#1915, category#1917, product#1919, amount#1921, status#1923, order_date#1925])\n",
            "   +- Sort [order_id#37 ASC NULLS FIRST], false, 0\n",
            "      +- Exchange hashpartitioning(order_id#37, 200), ENSURE_REQUIREMENTS, [plan_id=1548]\n",
            "         +- SortAggregate(key=[order_id#37], functions=[partial_first(customer_id#38, false), partial_first(city#79, false), partial_first(category#80, false), partial_first(product#81, false), partial_first(amount#115, false), partial_first(status#44, false), partial_first(order_date#1467, false)], output=[order_id#37, first#1940, valueSet#1941, first#1942, valueSet#1943, first#1944, valueSet#1945, first#1946, valueSet#1947, first#1948, valueSet#1949, first#1950, valueSet#1951, first#1952, valueSet#1953])\n",
            "            +- Sort [order_id#37 ASC NULLS FIRST], false, 0\n",
            "               +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, amount#115, status#44, coalesce(cast(gettimestamp(order_date#1305, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#1305, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#1305, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#1305, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#1467]\n",
            "                  +- Project [order_id#37, customer_id#38, city#79, category#80, product#81, if ((_common_expr_0#1911 = )) null else cast(_common_expr_0#1911 as int) AS amount#115, status#44, coalesce(cast(gettimestamp(order_date#43, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#43, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#43, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#43, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#1305]\n",
            "                     +- Project [trim(order_id#17, None) AS order_id#37, trim(customer_id#18, None) AS customer_id#38, initcap(lower(trim(city#19, None))) AS city#79, lower(trim(category#20, None)) AS category#80, lower(trim(product#21, None)) AS product#81, trim(order_date#23, None) AS order_date#43, trim(status#24, None) AS status#44, regexp_replace(trim(amount#22, None), [^0-9], , 1) AS _common_expr_0#1911]\n",
            "                        +- Filter ((isnotnull(trim(order_id#17, None)) AND isnotnull(coalesce(cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(coalesce(cast(gettimestamp(trim(order_date#23, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(trim(order_date#23, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)))) AND if ((regexp_replace(trim(amount#22, None), [^0-9], , 1) = )) false else isnotnull(cast(regexp_replace(trim(amount#22, None), [^0-9], , 1) as int)))\n",
            "                           +- FileScan csv [order_id#17,customer_id#18,city#19,category#20,product#21,amount#22,order_date#23,status#24] Batched: false, DataFilters: [isnotnull(trim(order_id#17, None)), isnotnull(coalesce(cast(gettimestamp(coalesce(cast(gettimest..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/orders_raw.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<order_id:string,customer_id:string,city:string,category:string,product:string,amount:strin...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Apply repartitioning to optimize aggregations.\n"
      ],
      "metadata": {
        "id": "Ev-B7CUO3k5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_completed.repartition(col(\"city\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmcQ4KRC3nse",
        "outputId": "44fbd73d-616e-4702-afe7-38ddb6a8208c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|   order_id|customer_id|     city|   category|    product|amount|   status|order_date|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "|ORD00000008|    C000008|Bangalore|    fashion|      jeans| 10563|Completed|2024-01-09|\n",
            "|ORD00000010|    C000010|Bangalore|    grocery|      sugar| 66576|Completed|2024-01-11|\n",
            "|ORD00000012|    C000012|Bangalore|    grocery|      sugar| 84768|Completed|2024-01-13|\n",
            "|ORD00000017|    C000017|Bangalore|    grocery|        oil| 69582|Completed|2024-01-18|\n",
            "|ORD00000024|    C000024|Bangalore|       home|      mixer| 18082|Completed|2024-01-25|\n",
            "|ORD00000025|    C000025|Bangalore|       home|airpurifier| 58248|Completed|2024-01-26|\n",
            "|ORD00000124|    C000124|Bangalore|    grocery|      sugar| 54296|Completed|2024-01-05|\n",
            "|ORD00000159|    C000159|Bangalore|electronics|     tablet| 89397|Completed|2024-02-09|\n",
            "|ORD00000161|    C000161|Bangalore|electronics|     mobile| 12000|Completed|2024-02-11|\n",
            "|ORD00000196|    C000196|Bangalore|       home|     vacuum| 70321|Completed|2024-01-17|\n",
            "|ORD00000201|    C000201|Bangalore|electronics|     mobile| 27502|Completed|2024-01-22|\n",
            "|ORD00000212|    C000212|Bangalore|electronics|     mobile| 59529|Completed|2024-02-02|\n",
            "|ORD00000215|    C000215|Bangalore|       home|      mixer| 37102|Completed|2024-02-05|\n",
            "|ORD00000223|    C000223|Bangalore|       home|      mixer| 28478|Completed|2024-02-13|\n",
            "|ORD00000237|    C000237|Bangalore|electronics|     laptop| 72945|Completed|2024-02-27|\n",
            "|ORD00000239|    C000239|Bangalore|electronics|     tablet| 32659|Completed|2024-02-29|\n",
            "|ORD00000241|    C000241|Bangalore|electronics|     tablet| 26022|Completed|2024-01-02|\n",
            "|ORD00000255|    C000255|Bangalore|    grocery|       rice|  6742|Completed|2024-01-16|\n",
            "|ORD00000268|    C000268|Bangalore|       home|airpurifier| 32698|Completed|2024-01-29|\n",
            "|ORD00000269|    C000269|Bangalore|       home|     vacuum| 68737|Completed|2024-01-30|\n",
            "+-----------+-----------+---------+-----------+-----------+------+---------+----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Justify where caching should be applied and why."
      ],
      "metadata": {
        "id": "VIQIBWMA3oEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_completed.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S3v3cql3pDO",
        "outputId": "c27a3428-5efa-478b-e14e-bd23e84c636d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[order_id: string, customer_id: string, city: string, category: string, product: string, amount: int, status: string, order_date: date]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 5 — Analytics\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qys8lsmA3umE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Calculate total revenue per city.\n"
      ],
      "metadata": {
        "id": "XxYbeDGe5uCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "df_completed.groupBy(\"city\").agg(sum(\"amount\").alias(\"total_revenue\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVHHcFZq5tiq",
        "outputId": "4fedd0a8-ce65-42f9-e5fc-00cc77ef392d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|     city|total_revenue|\n",
            "+---------+-------------+\n",
            "|Bangalore|   1614502422|\n",
            "|  Chennai|   1614928816|\n",
            "|   Mumbai|   1612372385|\n",
            "|  Kolkata|   1610016642|\n",
            "|     Pune|   1631286681|\n",
            "|    Delhi|   1623209640|\n",
            "|Hyderabad|   1629316412|\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Calculate total revenue per category.\n"
      ],
      "metadata": {
        "id": "8L22XV1Y5vs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_category = df_completed.groupBy(\"category\").agg(sum(\"amount\").alias(\"total_revenue\"))\n",
        "revenue_per_category.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLiFN80U5xi2",
        "outputId": "5848960a-13ef-4fbb-f55a-ea8112bde575"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+\n",
            "|   category|total_revenue|\n",
            "+-----------+-------------+\n",
            "|    grocery|   2841412668|\n",
            "|electronics|   2842335554|\n",
            "|       home|   2842762769|\n",
            "|    fashion|   2809122007|\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Identify top 5 products by revenue.\n"
      ],
      "metadata": {
        "id": "LGsu81Vp5yEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_product = df_completed.groupBy(\"product\").agg(sum(\"amount\").alias(\"total_revenue\"))\\\n",
        ".orderBy(col(\"total_revenue\").desc())\n",
        "revenue_product.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urpPmFT46Em_",
        "outputId": "2675606a-d546-4c86-880f-7fc13133ca83"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+\n",
            "|product|total_revenue|\n",
            "+-------+-------------+\n",
            "|    oil|    955294283|\n",
            "| laptop|    955061707|\n",
            "| tablet|    951653603|\n",
            "| vacuum|    950475394|\n",
            "|  mixer|    948801483|\n",
            "+-------+-------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Calculate average order value per city"
      ],
      "metadata": {
        "id": "fKm5HYGJ6E8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "average_order_value_per_city = df_completed.groupBy(\"city\").agg(avg(\"amount\").alias(\"average_order_value\"))\n",
        "average_order_value_per_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POVGRtGB6Fq6",
        "outputId": "6d43b952-2a47-47c8-b1c0-f41b9148092b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+\n",
            "|     city|average_order_value|\n",
            "+---------+-------------------+\n",
            "|Bangalore|  44089.20019661924|\n",
            "|  Chennai|  43606.65377760976|\n",
            "|   Mumbai| 43722.981397619114|\n",
            "|  Kolkata|  43719.56340628904|\n",
            "|     Pune|  43917.90547598535|\n",
            "|    Delhi| 43792.414611773595|\n",
            "|Hyderabad|  43718.91198883761|\n",
            "+---------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 6 — Window Functions\n"
      ],
      "metadata": {
        "id": "lrZoH8fB6kwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Rank cities by total revenue.\n"
      ],
      "metadata": {
        "id": "2bZ6Kjty6yQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, rank\n",
        "window_city = Window.orderBy(col(\"total_revenue\").desc())\n",
        "ranked_cities = revenue_per_category.withColumn(\"rank\", rank().over(window_city))\n",
        "ranked_cities.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27qu27Dh6z8i",
        "outputId": "9f312682-53ab-407c-86de-5165955560a5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+----+\n",
            "|   category|total_revenue|rank|\n",
            "+-----------+-------------+----+\n",
            "|       home|   2842762769|   1|\n",
            "|electronics|   2842335554|   2|\n",
            "|    grocery|   2841412668|   3|\n",
            "|    fashion|   2809122007|   4|\n",
            "+-----------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Rank products within each category by revenue.\n"
      ],
      "metadata": {
        "id": "51d5vSmQ60Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_cat = Window.partitionBy(\"category\").orderBy(col(\"total_revenue\").desc())\n",
        "ranked_products = df_completed.groupBy(\"category\", \"product\").agg(sum(\"amount\").alias(\"total_revenue\"))\\\n",
        ".withColumn(\"rank\", rank().over(window_cat))\n",
        "ranked_products.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kImr3W6i62Bc",
        "outputId": "d06ec8d2-ee87-45c8-a1b9-79dea3c9ddba"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+-------------+----+\n",
            "|   category|    product|total_revenue|rank|\n",
            "+-----------+-----------+-------------+----+\n",
            "|electronics|     laptop|    955061707|   1|\n",
            "|electronics|     tablet|    951653603|   2|\n",
            "|electronics|     mobile|    935620244|   3|\n",
            "|    fashion|      jeans|    942574809|   1|\n",
            "|    fashion|      shoes|    937880299|   2|\n",
            "|    fashion|     tshirt|    928666899|   3|\n",
            "|    grocery|        oil|    955294283|   1|\n",
            "|    grocery|       rice|    945818225|   2|\n",
            "|    grocery|      sugar|    940300160|   3|\n",
            "|       home|     vacuum|    950475394|   1|\n",
            "|       home|      mixer|    948801483|   2|\n",
            "|       home|airpurifier|    943485892|   3|\n",
            "+-----------+-----------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Identify the top product per category."
      ],
      "metadata": {
        "id": "9J41EZKS62aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_product_per_category = ranked_products.filter(col(\"rank\") == 1).drop(\"rank\")\n",
        "top_product_per_category.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kADJ1_5u63Qr",
        "outputId": "fbd3d88b-ec29-4766-df48-69a8bf9f38b3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+\n",
            "|   category|product|total_revenue|\n",
            "+-----------+-------+-------------+\n",
            "|electronics| laptop|    955061707|\n",
            "|    fashion|  jeans|    942574809|\n",
            "|    grocery|    oil|    955294283|\n",
            "|       home| vacuum|    950475394|\n",
            "+-----------+-------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 7 — Storage Strategy\n"
      ],
      "metadata": {
        "id": "8aXMytUe86nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write the cleaned dataset to Parquet partitioned by city .\n"
      ],
      "metadata": {
        "id": "hNmyws1_9DzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_completed.write \\\n",
        ".partitionBy(\"city\") \\\n",
        ".mode(\"overwrite\") \\\n",
        ".parquet(\"/content/orders_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "0pcD06gS820Y"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write aggregated analytics to ORC.\n"
      ],
      "metadata": {
        "id": "E006wTqh9GIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_category.write\\\n",
        ".mode(\"overwrite\") \\\n",
        ".orc(\"/content/orders_analytics.orc\")"
      ],
      "metadata": {
        "id": "o2hG6quf9IYz"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Explain why CSV is not suitable for analytics output.\n"
      ],
      "metadata": {
        "id": "3LOIu7rQ9Ivz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#no schema\n",
        "#no compression\n",
        "#no predicate pushdown\n",
        "#slow scans\n",
        "#larger storage"
      ],
      "metadata": {
        "id": "YzTjeZLs9KnR"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 8 — Debugging & Reasoning\n"
      ],
      "metadata": {
        "id": "W9W8GHpQ9K7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Explain why the following line causes failure:\n",
        "df = df.filter(df.amount > 50000).show()\n"
      ],
      "metadata": {
        "id": "GOHGrrRq9NvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#If 'amount' is still of StringType (before our cleaning step), comparing it to an Integer (50000) forces Spark to cast the column to Integer implicitly.\n",
        "#If the column contains non-numeric strings (like 'invalid'), the cast fails.\n",
        "#In ANSI mode (spark.sql.ansi.enabled=true), this throws a NumberFormatException and stops the job.\n",
        "#Even without ANSI mode, it converts values to NULL, leading to incorrect results."
      ],
      "metadata": {
        "id": "1djrx_aj9NAE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Describe how you would debug a slow Spark job.\n"
      ],
      "metadata": {
        "id": "E71Die-09Pnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Spark UI: Check 'Stages' to identify which specific stage is lagging.\n",
        "#2. Skew Analysis: Look at the task duration distribution. If Max Duration >> Median Duration, a single task is stuck on skewed data (e.g., one city has 90% of orders)."
      ],
      "metadata": {
        "id": "O-sm3BUN9RAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Identify risks of over-caching DataFrames"
      ],
      "metadata": {
        "id": "xJz3MvVO9RVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#memory pressure\n",
        "#disk spills\n",
        "#slower GC\n",
        "#eviction of useful cached data"
      ],
      "metadata": {
        "id": "I-EVQnU49R-i"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}